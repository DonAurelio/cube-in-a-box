{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cube in a Box\n",
    "\n",
    "### Basic Functionality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook introduces the following concepts:\n",
    " - The Datacube module\n",
    " - Loading Data\n",
    " - Visualising Data\n",
    " - Filtering out cloud and occluded land pixels\n",
    " - Visualising nDVI trough time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube # Load the datacube library\n",
    "import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.utils import (\n",
    "    lat_lon_to_epsg,\n",
    "    three_band_image,\n",
    "    load_config_extents,\n",
    "    transform_to_wgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the extent parameters used to index data cube in the box data.\n",
    "extents, bbox = load_config_extents('/opt/odc/data/configIndex.txt')\n",
    "\n",
    "lon_min, lon_max, lat_min, lat_max = extents\n",
    "# Get the EPSG of a WGS UTM coordinate reference system that is appropriate for our data\n",
    "EPSG = lat_lon_to_epsg(lat_max,lon_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an instance of the datacube.\n",
    "dc = datacube.Datacube(app='dc-visualize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sample below we use the datacube.load command to load the RGB and Quality Assurance(QA) bands from the AWS Landsat archive. Landsat 8 has a return period of 16 days capturing over 24 snapshots a year so care should be taken when requesting a datacube as large geographical or time extents can quickly over fill memory and generate huge lag. \n",
    "\n",
    "For our first visualisation we'll load a single time slice of the full geographical extent indexed and then proceed to select a smaller zone to explore through time.\n",
    "\n",
    "It should be noted that images on AWS are referenced to WGS 84 so the extent bounds that are entered into the datacube.load() must match the coordinate system in which they're being stored. \n",
    "\n",
    "The datacube.load() command also reprojects into a coordinate system in the below datacube load we automatically generate an EPSG code from the lat/long of the provided extent. \n",
    "\n",
    "If you'd like to visualize other bands add any of the below measurements to the `datacube.load(measurements= ...`:\n",
    "\n",
    "Landsat 8 measurement options are:\n",
    "\n",
    "             ('1', 'coastal_aerosol')\n",
    "             ('2', 'blue')\n",
    "             ('3', 'green')\n",
    "             ('4', 'red')\n",
    "             ('5', 'nir')\n",
    "             ('6', 'swir1')\n",
    "             ('7', 'swir2')\n",
    "             ('8', 'panchromatic')\n",
    "             ('9', 'cirrus')\n",
    "             ('10', 'lwir1')\n",
    "             ('11', 'lwir2')\n",
    "             ('QUALITY', 'quality')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset <id=591c6c5e-0012-5ebf-a39a-5bc93594a0eb type=S2A_MSIL2A location=https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/2020/S2A_30NXM_20200211_0_L2A/B04.tif>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product='S2A_MSIL2A'\n",
    "datasets = dc.find_datasets(product=product)\n",
    "datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'e3beef06-3251-51ec-bc22-e2b2ccac6ca7',\n",
       " 'image': {'bands': {'B01': {'path': 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a/2020/S2A_30NXM_20200211_0_L2A/B01.tif',\n",
       "    'layer': 1},\n",
       "   'B02': {'path': 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a/2020/S2A_30NXM_20200211_0_L2A/B02.tif',\n",
       "    'layer': 1},\n",
       "   'B03': {'path': 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a/2020/S2A_30NXM_20200211_0_L2A/B03.tif',\n",
       "    'layer': 1},\n",
       "   'B04': {'path': 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a/2020/S2A_30NXM_20200211_0_L2A/B04.tif',\n",
       "    'layer': 1},\n",
       "   'B05': {'path': 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a/2020/S2A_30NXM_20200211_0_L2A/B05.tif',\n",
       "    'layer': 1},\n",
       "   'B06': {'path': 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a/2020/S2A_30NXM_20200211_0_L2A/B06.tif',\n",
       "    'layer': 1},\n",
       "   'B07': {'path': 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a/2020/S2A_30NXM_20200211_0_L2A/B07.tif',\n",
       "    'layer': 1},\n",
       "   'B08': {'path': 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a/2020/S2A_30NXM_20200211_0_L2A/B08.tif',\n",
       "    'layer': 1},\n",
       "   'B09': {'path': 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a/2020/S2A_30NXM_20200211_0_L2A/B09.tif',\n",
       "    'layer': 1},\n",
       "   'B10': {'path': 's3://sentinel-s2-l2a/tiles/30/N/XM/2020/2/11/0/R60m/B10.jp2',\n",
       "    'layer': 1},\n",
       "   'B11': {'path': 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a/2020/S2A_30NXM_20200211_0_L2A/B11.tif',\n",
       "    'layer': 1},\n",
       "   'B12': {'path': 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a/2020/S2A_30NXM_20200211_0_L2A/B12.tif',\n",
       "    'layer': 1},\n",
       "   'B8A': {'path': 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a/2020/S2A_30NXM_20200211_0_L2A/B8A.tif',\n",
       "    'layer': 1}}},\n",
       " 'label': 'S2A_MSIL2A_20200211T102141_N0214_R065_T30NXM_20200211T124239',\n",
       " 'extent': {'coord': {'ll': {'lat': 5.266007882805496,\n",
       "    'lon': -2.1093749999999996},\n",
       "   'lr': {'lat': 5.266007882805496, 'lon': -1.0546874999999998},\n",
       "   'ul': {'lat': 6.402648405963895, 'lon': -2.1093749999999996},\n",
       "   'ur': {'lat': 6.402648405963895, 'lon': -1.0546874999999998}},\n",
       "  'to_dt': '2020-02-11T10:39:22.031000+00:00',\n",
       "  'from_dt': '2020-02-11T10:39:22.031000+00:00',\n",
       "  'center_dt': '2020-02-11T10:39:22.031000+00:00'},\n",
       " 'format': {'name': 'GeoTiff'},\n",
       " 'lineage': {'source_datasets': {}},\n",
       " 'platform': {'code': 'sentinel-2'},\n",
       " 'instrument': {'name': 'msi'},\n",
       " 'creation_dt': '2020-02-11T10:39:22.031000+00:00',\n",
       " 'grid_spatial': {'projection': {'geo_ref_points': {'ll': {'x': -234814.55089206144,\n",
       "     'y': 587036.377230154},\n",
       "    'lr': {'x': -117407.27544603072, 'y': 587036.377230154},\n",
       "    'ul': {'x': -234814.55089206144, 'y': 714227.5922966873},\n",
       "    'ur': {'x': -117407.27544603072, 'y': 714227.5922966873}},\n",
       "   'spatial_reference': 'EPSG:0'}},\n",
       " 'product_type': 'S2A_MSIL2A',\n",
       " 'processing_level': 'Level-2'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0].metadata_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.61 s, sys: 1.28 s, total: 2.89 s\n",
      "Wall time: 44.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# The defaults should find two datasets for spatial extent and time period\n",
    "dataset = dc.load(\n",
    "    product=product,\n",
    "    id=datasets[0].id,\n",
    "    output_crs=\"epsg:4326\",\n",
    "    resolution=[-0.01, 0.01]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (latitude: 101, longitude: 100, time: 1)\n",
       "Coordinates:\n",
       "  * time       (time) datetime64[ns] 2020-02-11T10:39:22.031000\n",
       "  * latitude   (latitude) float64 6.335 6.325 6.315 6.305 ... 5.355 5.345 5.335\n",
       "  * longitude  (longitude) float64 -2.095 -2.085 -2.075 ... -1.125 -1.115 -1.105\n",
       "Data variables:\n",
       "    B01        (time, latitude, longitude) uint16 0 0 0 0 ... 1366 1530 1512\n",
       "    B02        (time, latitude, longitude) uint16 0 0 0 0 0 0 0 ... 0 0 0 0 0 0\n",
       "    B03        (time, latitude, longitude) uint16 0 0 0 0 0 0 0 ... 0 0 0 0 0 0\n",
       "    B04        (time, latitude, longitude) uint16 0 0 0 0 0 0 0 ... 0 0 0 0 0 0\n",
       "    B05        (time, latitude, longitude) uint16 0 0 0 0 0 0 0 ... 0 0 0 0 0 0\n",
       "    B06        (time, latitude, longitude) uint16 0 0 0 0 0 0 0 ... 0 0 0 0 0 0\n",
       "    B07        (time, latitude, longitude) uint16 0 0 0 0 0 0 0 ... 0 0 0 0 0 0\n",
       "    B08        (time, latitude, longitude) uint16 0 0 0 0 0 0 0 ... 0 0 0 0 0 0\n",
       "    B8A        (time, latitude, longitude) uint16 0 0 0 0 0 0 0 ... 0 0 0 0 0 0\n",
       "    B09        (time, latitude, longitude) uint16 0 0 0 0 ... 2127 2675 2449\n",
       "    B11        (time, latitude, longitude) uint16 0 0 0 0 0 0 0 ... 0 0 0 0 0 0\n",
       "    B12        (time, latitude, longitude) uint16 0 0 0 0 0 0 0 ... 0 0 0 0 0 0\n",
       "    SCL        (time, latitude, longitude) uint8 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0\n",
       "Attributes:\n",
       "    crs:      epsg:4326"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bits</th>\n",
       "      <th>values</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sca</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'1': 'saturated or defective', '2': 'dark are...</td>\n",
       "      <td>Sen2Cor Scene Classification</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         bits  \\\n",
       "sca  [0, 1, 2, 3, 4, 5, 6, 7]   \n",
       "\n",
       "                                                values  \\\n",
       "sca  {'1': 'saturated or defective', '2': 'dark are...   \n",
       "\n",
       "                      description  \n",
       "sca  Sen2Cor Scene Classification  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datacube.storage import masking\n",
    "\n",
    "masking.describe_variable_flags(dataset.SCL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword can't be an expression (<ipython-input-20-6955316badb3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-6955316badb3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    masking.make_mask(dataset.SCL, 'saturated or defective'=True)\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword can't be an expression\n"
     ]
    }
   ],
   "source": [
    "masking.make_mask(dataset.SCL, 'saturated or defective'=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Please wait patiently for the above to finish (it's finished when the &ast; is gone).*\n",
    "\n",
    "The `datacube.load()` command returns an [xarray](https://xarray.pydata.org/en/stable/). The key to building effective ODC algorithms is to master the use of the xarray. Please click on the documention to find out more otherwise a number of examples are provided below.\n",
    "\n",
    "The xarray for landsat contains the dimensions of X, Y and Time - for each combination of these dimensions data listed as \"Data Variables\" can be retrieved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset) # Viewing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying the xarray using index 0 will retrieve the first record of each dimension\n",
    "print(dataset.isel(time=[0], x=[0], y=[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# Extract a cross-section of y measurements from the first timestep and the second row of x values.\n",
    "cross_section = dataset.isel(time=0).sel(x=[1], method='nearest')\n",
    "\n",
    "print(cross_section) \n",
    "cross_section.red.plot() # Plotting the measurements from the red band."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll explore [Landsat 8 quality band](https://landsat.usgs.gov/collectionqualityband), each pixel in the QA band contains unsigned integers that represent bit-packed combinations of surface, atmospheric, and sensor conditions that can affect the overall usefulness of a given pixel.\n",
    "\n",
    "Used effectively, QA bits improve the integrity of science investigations by indicating which pixels might be affected by instrument artifacts or subject to cloud contamination. The ODC has in built methods that transform the metadata of a specific product to a libary of masking templates. For example, you are able to build a cloud mask directly from the ODC library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datacube.storage import masking  # Import masking capabilities\n",
    "print (masking.describe_variable_flags(dataset)) #D escribe the masks available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask around all pixels deemed good according to parameters around cloud cover and saturation.\n",
    "clean_pixel_mask = masking.make_mask(\n",
    "    dataset.quality,\n",
    "    cloud=False,\n",
    "    radiometric_saturation='none',\n",
    "    terrain_occlusion = False)\n",
    "\n",
    "print(clean_pixel_mask)\n",
    "\n",
    "masked_cloud = dataset.where(clean_pixel_mask)\n",
    "\n",
    "print(masked_cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll display the RGB bands that we have extracted from our cube for the first time slice (time = 0) in order to visualise a comprehendible RGB image we apply a histogram equalisation on each band before displaying. We'll also create visualisation of the pixels that are occluding land areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "def callback(event):\n",
    "    global x, y\n",
    "    x, y = int(event.xdata + 0.5), int(event.ydata + 0.5)\n",
    "\n",
    "time = 0\n",
    "img_toshowNoMask = three_band_image(masked_cloud,bands = ['red', 'green', 'blue'], time = time)\n",
    "img_toshow = three_band_image(dataset, bands = ['red', 'green', 'blue'], time = time)\n",
    "fig = plt.figure(1, [10,20])\n",
    "fig.canvas.mpl_connect('button_press_event', callback)\n",
    "\n",
    "plt.subplot(211)\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"All Pixels\", fontweight = 'bold', fontsize = 16)\n",
    "ax.set_xticklabels(dataset.x.values)\n",
    "ax.set_yticklabels(dataset.y.values)\n",
    "ax.set_xlabel('Easting', fontweight = 'bold')\n",
    "ax.set_ylabel('Northing', fontweight = 'bold')\n",
    "\n",
    "plt.imshow(img_toshow)\n",
    "\n",
    "plt.subplot(212)\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Artifacts Filtered Out\", fontweight = 'bold', fontsize = 16)\n",
    "ax.set_xticklabels(dataset.x.values)\n",
    "ax.set_yticklabels(dataset.y.values)\n",
    "ax.set_xlabel('Easting', fontweight = 'bold')\n",
    "ax.set_ylabel('Northing', fontweight = 'bold')\n",
    "plt.imshow(img_toshowNoMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll select a single pixel from any of the above images and drill through the time dimension to calculate the change in nDVI.\n",
    "\n",
    "Before running the below cell click on a location in the above visualisations to select an area to explore through time with a 100x100 lens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixelDrillExtent = []\n",
    "for i in [[x , y], [x + 100, y + 100]]:\n",
    "    xI, yI = i\n",
    "    getLong = dataset.isel(x=[xI], y=[yI]).isel(time=0).x.values\n",
    "    getLat = dataset.isel(x=[xI], y=[yI]).isel(time=0).y.values\n",
    "    \n",
    "    pixelDrillExtent.append(transform_to_wgs(getLong, getLat,int(EPSG)))\n",
    "print(pixelDrillExtent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By expanding out the time extent and limiting the x,y extent in the datacube.load() we are able to retrieve cross section through time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load 6 months of data\n",
    "drill_range = ('2019-01-01', '2019-07-01')\n",
    "dataset_drill = dc.load(\n",
    "    product='ls8_usgs_level1_scene',\n",
    "    x=(pixelDrillExtent[0][0], pixelDrillExtent[1][0]),\n",
    "    y=(pixelDrillExtent[0][1], pixelDrillExtent[1][1]), \n",
    "    output_crs='epsg:28355',\n",
    "    resolution=(-30,30),\n",
    "    time=drill_range,\n",
    "    measurements=('red','nir','quality')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_drill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use band math to derive NDVI and mask out occluded measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "red = dataset_drill.red.where(dataset_drill.red != dataset_drill.red.attrs['nodata'])\n",
    "nir = dataset_drill.nir.where(dataset_drill.nir != dataset_drill.nir.attrs['nodata'])\n",
    "\n",
    "cloud_free = masking.make_mask(\n",
    "    dataset_drill.quality,\n",
    "    cloud=False,\n",
    "    radiometric_saturation='none',\n",
    "    terrain_occlusion=False\n",
    ")\n",
    "\n",
    "ndvi = ((nir - red) / (nir + red)).where(cloud_free).dropna('time')\n",
    "ndvi.isel(x=[3], y=[6]).plot() #Plots the change in nDVI over the time extent using the array index.\n",
    "#ndvi.isel(x =465105, y=5194065).plot() #Plots the change in nDVI over the time extent using the X and Y coordinate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot out a crossection accross the y axis of an x coordinate over a time extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "ndvi.isel(x=[0]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
